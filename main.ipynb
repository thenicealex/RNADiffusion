{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.rna_model.model_slim import ESM2\n",
    "from models.rna_model import rna_esm\n",
    "from models.rna_model.evo.tokenization import Vocab, mapdict\n",
    "from models.rna_model.config import TransformerConfig, OptimizerConfig, Config, DataConfig, ProduceConfig, TrainConfig, LoggingConfig\n",
    "esm_path = \"/home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\"\n",
    "class RNAESM2(nn.Module):\n",
    "    def __init__(self, esm_ckpt, device=\"cuda:0\"):\n",
    "        super(RNAESM2, self).__init__()\n",
    "        self.device = device\n",
    "        if esm_ckpt is None:\n",
    "            raise ValueError(\"Please provide a valid RNA-ESM2 checkpoint\")\n",
    "        else:\n",
    "            self.esm_ckpt = esm_ckpt\n",
    "        self.model, self.rna_map_vocab, self.rna_alphabet = self.__init_model()\n",
    "\n",
    "    def __init_model(self):\n",
    "        _, protein_alphabet = rna_esm.pretrained.esm2_t30_150M_UR50D()\n",
    "        rna_alphabet = rna_esm.data.Alphabet.from_architecture(\"rna-esm\")\n",
    "        protein_vocab = Vocab.from_esm_alphabet(protein_alphabet)\n",
    "        rna_vocab = Vocab.from_esm_alphabet(rna_alphabet)\n",
    "        rna_map_dict = mapdict(protein_vocab, rna_vocab)\n",
    "        rna_map_vocab = Vocab.from_esm_alphabet(rna_alphabet, rna_map_dict)\n",
    "        model = ESM2(\n",
    "            vocab=protein_vocab,\n",
    "            model_config=TransformerConfig(),\n",
    "            optimizer_config=OptimizerConfig(),\n",
    "            contact_train_data=None,\n",
    "            token_dropout=True,\n",
    "        )\n",
    "        print(f\"Loading RNA-ESM2 model: {self.esm_ckpt}\")\n",
    "        model.load_state_dict(\n",
    "            torch.load(self.esm_ckpt, map_location=\"cpu\")[\n",
    "                \"state_dict\"\n",
    "            ],\n",
    "            strict=True,\n",
    "        )\n",
    "        return model, rna_map_vocab, rna_alphabet\n",
    "    \n",
    "    def forward(self, data_seq_raw, set_max_len=80):\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        output = dict()\n",
    "        for i, seq in enumerate(data_seq_raw):\n",
    "            if \"Y\" in seq:\n",
    "                data_seq_raw[i] = seq.replace(\"Y\", \"N\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tokens = torch.from_numpy(self.rna_map_vocab.encode(data_seq_raw))\n",
    "            infer = self.model(\n",
    "                tokens.to(self.device), repr_layers=[30], return_contacts=True\n",
    "            )\n",
    "            embedding = infer[\"representations\"][30]\n",
    "            attention = infer[\"attentions\"]\n",
    "\n",
    "            try:\n",
    "                embedding = F.softmax(embedding, dim=-1)\n",
    "            except:\n",
    "                ValueError(\"Error in softmax\")\n",
    "\n",
    "            output[\"embedding\"] = embedding\n",
    "            output[\"attention\"] = attention\n",
    "            output[\"contacts\"] = infer[\"contacts\"]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 [0, '1wz2_C', 'GCGGGGGUUGCCGAGCCUGGUCAAAGGCGGGGGACUCAAGAUCCCCUCCCGUAGGGGUUCCGGGGUUCGAAUCCCCGCCCCCGCACCA', [[0, 83], [1, 82], [2, 81], [3, 80], [4, 79], [5, 78], [6, 77], [7, 13], [8, 12], [9, 27], [10, 26], [11, 25], [12, 24], [13, 23], [14, 21], [14, 23], [14, 59], [18, 66], [19, 67], [21, 59], [23, 58], [28, 46], [29, 45], [30, 44], [31, 43], [32, 42], [33, 41], [47, 56], [48, 55], [49, 54], [60, 76], [61, 75], [62, 74], [63, 73], [64, 72], [65, 69]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocab contains non-special token of length > 1: <null_1>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNA-ESM2 model: /home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\n",
      "<generator object Module.parameters at 0x7f89e46dd820>\n",
      "[0.02433111 0.01235184 1.        ] 231\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "base_path = \"/home/fkli/RNAdata\"\n",
    "with open(base_path + '/RNAcmap2_231.pkl', 'rb') as f:\n",
    "    true_labels_pdb = pkl.load(f)\n",
    "data_nums = len(true_labels_pdb)\n",
    "print(data_nums, true_labels_pdb[0])\n",
    "\n",
    "model = RNAESM2(esm_path)\n",
    "model.eval()\n",
    "\n",
    "def pred_map_to_pair(pred_contact_map, seq_len):\n",
    "    pair_list = [[i, j, pred_contact_map[i][j]] for i in range(seq_len) for j in range(i)]\n",
    "    pair_list.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [[x[1], x[0]] for x in pair_list]\n",
    "count = 0\n",
    "save_all_bps = []\n",
    "for data in true_labels_pdb:\n",
    "    true_pairs = [i for i in data[3] if abs(i[0]-i[1]) > 3]  # non-local base-pairs\n",
    "    # print(true_pairs)\n",
    "    L = len(data[2])\n",
    "    # print(f\"count is {count}, seq is {data[2]}, seq len is {L}\")\n",
    "    with torch.no_grad ():\n",
    "        p_contact = model([data[2]])['contacts'].cpu().float()\n",
    "    p_contact = torch.Tensor.tolist(p_contact.squeeze())\n",
    "    pair_list = pred_map_to_pair(p_contact, L)\n",
    "    n = int(L/2)\n",
    "    positive_pairs = pair_list[:]\n",
    "    # print(positive_pairs)\n",
    "    negative_pairs = pair_list[n:]\n",
    "    tp = 0;fp = 0;fn = 0\n",
    "    correct_pairs = []\n",
    "    for i,I in enumerate(positive_pairs):\n",
    "        if I in true_pairs:\n",
    "            tp +=1\n",
    "            correct_pairs.append(I)\n",
    "        elif I not in true_pairs:\n",
    "            fp += 1\n",
    "            # print(tp)\n",
    "    for i,I in enumerate(true_pairs):\n",
    "        if I not in positive_pairs:\n",
    "            fn += 1\n",
    "    tn = L*L- tp - fp - fn\n",
    "\n",
    "    try:\n",
    "        pre = tp / (tp + fp)\n",
    "        sen = tp / (tp + fn)\n",
    "        f1 = 2*((pre*sen)/(pre + sen))\n",
    "        #with np.errstate(invalid='ignore'):\n",
    "        mcc = ((tp * tn) - (fp * fn)) / np.sqrt(np.float64((tp + fp) * (tp + fn) * (tn + fn) * (tn + fp)))\n",
    "    except:\n",
    "        pre = 0\n",
    "        sen = 0\n",
    "        f1 = 0\n",
    "        mcc = 0; #print(k)\n",
    "    save_all_bps.append([f1, pre, sen])\n",
    "    count += 1\n",
    "all_metrics = np.mean(save_all_bps, axis=0) \n",
    "print(all_metrics, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0], [2, 1], [1, 0]]\n"
     ]
    }
   ],
   "source": [
    "predicted_map = [[1, 0, 1],  \n",
    "                 [0.1, 1, 0], \n",
    "                 [0.7, 0.4, 1.9]]\n",
    "def pred_map_to_pair(pred_contact_map, seq_len):\n",
    "    pair_list = [[i, j, pred_contact_map[i][j]] for i in range(seq_len) for j in range(i)]\n",
    "    pair_list.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [[x[0], x[1]] for x in pair_list]\n",
    "\n",
    "pair_list = pred_map_to_pair(predicted_map, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "datasets_path = \"/home/fkli/Projects/RNADiffFold/dataset/dataset.pkl\"\n",
    "with open(datasets_path, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_seq_len_list = [len(seq[2]) for seq in dataset[\"train_dataset\"]]\n",
    "train_seq_len_list.sort()\n",
    "train_seq_num = len(train_seq_len_list)\n",
    "print(f\"train seq num: {train_seq_num}\")\n",
    "my_x_ticks = np.arange(0, max(train_seq_len_list)+80, 80)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.xlabel('seq length')\n",
    "plt.ylabel('seq num')\n",
    "plt.hist(train_seq_len_list, bins=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_generator import RNADataset, diff_collate_fn, get_data_id\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from os.path import join\n",
    "\n",
    "DATA_PATH = \"/home/fkli/Projects/DiffRNA/datasets/batching\"\n",
    "train = RNADataset([join(DATA_PATH, \"train\")], upsampling=False)\n",
    "print(len(train))\n",
    "partial_collate_fn = partial(diff_collate_fn)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    # collate_fn=partial_collate_fn,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def rna_evaluation(preds, targets):\n",
    "    preds = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "    tp = torch.sum(preds * targets)\n",
    "    tn = torch.sum((1 - preds) * (1 - targets))\n",
    "    fp = torch.sum(preds * (1 - targets))\n",
    "    fn = torch.sum((1 - preds) * targets)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) # accuracy\n",
    "    prec = tp / (tp + fp)  # precision\n",
    "    recall = tp / (tp + fn)  # recall\n",
    "    sens = tp / (tp + fn)  # senstivity\n",
    "    spec = tn / (tn + fp)  # spec\n",
    "\n",
    "    F1 = 2 * ((prec * sens) / (prec + sens))\n",
    "    MCC = (tp * tn - fp * fn) / torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return accuracy, prec, recall, sens, spec, F1, MCC.cpu().item()\n",
    "    \n",
    "def padding_two(data_array, maxlen):\n",
    "    a, b = data_array.shape\n",
    "    # np.pad(array, ((before_1,after_1),……,(before_n,after_n),module)\n",
    "    return np.pad(data_array, ((0, maxlen - a), (0, maxlen - b)), \"constant\")\n",
    "\n",
    "d_path = \"/home/fkli/RNAdata/RNAcmap2/datasets/test\"\n",
    "i = 0\n",
    "FF = 0\n",
    "PP = 0\n",
    "model = RNAESM2(esm_path)\n",
    "model.eval()\n",
    "for file in os.listdir(d_path):\n",
    "    i += 1\n",
    "    file_name = os.path.join(d_path, file)\n",
    "\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    str = [seq_data[\"seq_raw\"] for seq_data in dataset]\n",
    "    seq_max_len = max(len(seq) for seq in str)\n",
    "    with torch.no_grad ():\n",
    "        p_contact = model(str, seq_max_len)['contacts'].cpu().float()\n",
    "    contact_map = [padding_two(seq_data[\"contact\"], seq_max_len) for seq_data in dataset]\n",
    "    test_no_train_tmp = [rna_evaluation( p_contact[i], contact_map[i]) for i in range(p_contact.shape[0])]\n",
    "    accuracy, prec, recall, sens, spec, F1, MCC = zip(*test_no_train_tmp)\n",
    "    precision = np.average(np.nan_to_num(np.array(prec)))\n",
    "    F1 = np.average(np.nan_to_num(np.array(F1)))\n",
    "    PP += precision\n",
    "    FF += F1\n",
    "    torch.cuda.empty_cache()\n",
    "print(FF/i, PP/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocab contains non-special token of length > 1: <null_1>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNA-ESM2 model: /home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\n",
      "load model from /home/fkli/RNAm/best_checkpoint_15.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.model import DiffusionRNA2dPrediction\n",
    "from models.rna_model.config import TransformerConfig, OptimizerConfig, Config, DataConfig, ProduceConfig, TrainConfig, LoggingConfig\n",
    "esm_path = \"/home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\"\n",
    "model = DiffusionRNA2dPrediction(\n",
    "    num_classes=2,\n",
    "    diffusion_dim=8,\n",
    "    cond_dim=8,\n",
    "    diffusion_steps=20,\n",
    "    dp_rate=0.0,\n",
    "    u_ckpt=\"/home/fkli/RNAm/ufold_train_alldata.pt\",\n",
    "    esm_ckpt=esm_path,\n",
    ")\n",
    "ckpt_path = '/home/fkli/RNAm/best_checkpoint_15.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(\"cuda:3\")\n",
    "print('load model from {}'.format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common.data_utils import contact_map_masks\n",
    "from torch.utils.data import DataLoader\n",
    "from data.data_generator import RNADataset, diff_collate_fn\n",
    "from functools import partial\n",
    "from common.loss_utils import rna_evaluation\n",
    "DATA_PATH = \"/home/fkli/RNAdata/RNAcmap2/datasets\"\n",
    "partial_collate_fn = partial(diff_collate_fn)\n",
    "test = RNADataset([os.path.join(DATA_PATH, \"test\")], upsampling=False)\n",
    "test_loader = DataLoader(\n",
    "    test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=partial_collate_fn,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "device = torch.device(\"cuda:3\")\n",
    "def model_test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_no_train = list()\n",
    "        total_name_list = list()\n",
    "        total_length_list = list()\n",
    "\n",
    "        for _, (contact, base_info, data_seq_raw, data_length, data_name, set_max_len, data_seq_encoding) in enumerate(test_loader):\n",
    "            total_name_list += [item for item in data_name]\n",
    "            total_length_list += [item.item() for item in data_length]\n",
    "\n",
    "            base_info = base_info.to(device)\n",
    "            matrix_rep = torch.zeros_like(contact)\n",
    "            data_length = data_length.to(device)\n",
    "            # data_seq_raw = data_seq_raw.to(device)\n",
    "            data_seq_encoding = data_seq_encoding.to(device)\n",
    "            contact_masks = contact_map_masks(data_length, matrix_rep).to(device)\n",
    "\n",
    "            # calculate contact loss\n",
    "            batch_size = contact.shape[0]\n",
    "            pred_x0, _ = model.sample(batch_size, base_info, data_seq_raw, set_max_len, contact_masks, data_seq_encoding)\n",
    "\n",
    "            pred_x0 = pred_x0.cpu().float()\n",
    "            test_no_train_tmp = list(map(lambda i: rna_evaluation(\n",
    "                pred_x0[i].squeeze(), contact.float()[i].squeeze()), range(pred_x0.shape[0])))\n",
    "            test_no_train += test_no_train_tmp\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        accuracy, prec, recall, sens, spec, F1, MCC = zip(*test_no_train)\n",
    "\n",
    "        f1_pre_rec_df = pd.DataFrame({'name': total_name_list,\n",
    "                                        'length': total_length_list,\n",
    "                                        'accuracy': list(np.array(accuracy)),\n",
    "                                        'precision': list(np.array(prec)),\n",
    "                                        'recall': list(np.array(recall)),\n",
    "                                        'sensitivity': list(np.array(sens)),\n",
    "                                        'specificity': list(np.array(spec)),\n",
    "                                        'f1': list(np.array(F1)),\n",
    "                                        'mcc': list(np.array(MCC))})\n",
    "\n",
    "        accuracy = np.average(np.nan_to_num(np.array(accuracy)))\n",
    "        precision = np.average(np.nan_to_num(np.array(prec)))\n",
    "        recall = np.average(np.nan_to_num(np.array(recall)))\n",
    "        sensitivity = np.average(np.nan_to_num(np.array(sens)))\n",
    "        specificity = np.average(np.nan_to_num(np.array(spec)))\n",
    "        F1 = np.average(np.nan_to_num(np.array(F1)))\n",
    "        MCC = np.average(np.nan_to_num(np.array(MCC)))\n",
    "\n",
    "        print('#' * 40)\n",
    "        print('Average testing accuracy: ', round(accuracy, 3))\n",
    "        print('Average testing F1 score: ', round(F1, 3))\n",
    "        print('Average testing precision: ', round(precision, 3))\n",
    "        print('Average testing recall: ', round(recall, 3))\n",
    "        print('Average testing sensitivity: ', round(sensitivity, 3))\n",
    "        print('Average testing specificity: ', round(specificity, 3))\n",
    "        print('#' * 40)\n",
    "        print('Average testing MCC', round(MCC, 3))\n",
    "        print('#' * 40)\n",
    "        print('')\n",
    "    \n",
    "    return {'f1': F1, 'precision': precision, 'recall': recall, 'sensitivity': sensitivity, 'specificity': specificity, 'accuracy': accuracy, 'mcc': MCC}, f1_pre_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 20/20 [00:00<00:00, 20.55it/s]\n",
      "sampling loop time step: 100%|██████████| 20/20 [00:00<00:00, 34.60it/s]\n",
      "sampling loop time step: 100%|██████████| 20/20 [00:01<00:00, 17.13it/s]\n",
      "sampling loop time step: 100%|██████████| 20/20 [00:02<00:00,  9.62it/s]\n",
      "sampling loop time step: 100%|██████████| 20/20 [00:00<00:00, 87.45it/s]\n",
      "sampling loop time step: 100%|██████████| 20/20 [00:00<00:00, 65.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Average testing accuracy:  0.996\n",
      "Average testing F1 score:  0.387\n",
      "Average testing precision:  0.386\n",
      "Average testing recall:  0.41\n",
      "Average testing sensitivity:  0.41\n",
      "Average testing specificity:  0.998\n",
      "########################################\n",
      "Average testing MCC 0.39\n",
      "########################################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'f1': 0.38667193,\n",
       "  'precision': 0.3858722,\n",
       "  'recall': 0.41010335,\n",
       "  'sensitivity': 0.41010335,\n",
       "  'specificity': 0.99806064,\n",
       "  'accuracy': 0.9962581,\n",
       "  'mcc': 0.39037907342436556},\n",
       "         name  length  accuracy  precision    recall  sensitivity  specificity  \\\n",
       " 0     5dcv_B      51  0.996094   0.400000  0.380952     0.380952     0.998119   \n",
       " 1     6p2h_A      69  0.992969   0.250000  0.142857     0.142857     0.997643   \n",
       " 2     2xdb_G      40  0.996562   0.214286  0.214286     0.214286     0.998277   \n",
       " 3     4x0b_B      77  0.994687   0.470588  0.500000     0.500000     0.997173   \n",
       " 4     6r47_A      50  0.996250   0.416667  0.227273     0.227273     0.998902   \n",
       " ..       ...     ...       ...        ...       ...          ...          ...   \n",
       " 226  4v88_A4     158  0.998008   0.346154  0.209302     0.209302     0.999335   \n",
       " 227   6n2v_A      99  0.997852   0.430769  0.608696     0.608696     0.998552   \n",
       " 228   6vmy_A     148  0.997539   0.487179  0.306452     0.306452     0.999217   \n",
       " 229   6mwn_A      92  0.997305   0.276923  0.450000     0.450000     0.998161   \n",
       " 230   4mgn_A      86  0.997891   0.272727  0.230769     0.230769     0.999061   \n",
       " \n",
       "            f1       mcc  \n",
       " 0    0.390244  0.388402  \n",
       " 1    0.181818  0.185646  \n",
       " 2    0.214286  0.212563  \n",
       " 3    0.484848  0.482405  \n",
       " 4    0.294118  0.306003  \n",
       " ..        ...       ...  \n",
       " 226  0.260870  0.268222  \n",
       " 227  0.504505  0.511034  \n",
       " 228  0.376238  0.385229  \n",
       " 229  0.342857  0.351739  \n",
       " 230  0.250000  0.249823  \n",
       " \n",
       " [231 rows x 9 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test()\n",
    "# f1_pre.to_csv(\n",
    "#     os.path.join(\"/home/fkli/\", f\"test.csv\"),\n",
    "#     index=False,\n",
    "#     header=False,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNADiffFold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
