{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models.rna_model.model_slim import ESM2\n",
    "from models.rna_model import rna_esm\n",
    "from models.rna_model.evo.tokenization import Vocab, mapdict\n",
    "from models.rna_model.config import TransformerConfig, OptimizerConfig, Config, DataConfig, ProduceConfig, TrainConfig, LoggingConfig\n",
    "\n",
    "from data.data_generator import RNADataset, diff_collate_fn, get_data_id\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import join\n",
    "import pickle\n",
    "\n",
    "from models.model import RNAESM2, RNAUNet\n",
    "unet_path = \"/home/fkli/RNAm/ufold_train_alldata.pt\"\n",
    "esm_path = \"/home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'bpRNA_RFAM_10645', 'seq_raw': 'UUAGCUCGCCAGUUAGCGAAGUCUGUCCCCACACGACAGAUAAUCGGGUGCAACUCCCGCCCCUUUUCCGAGGGUCA', 'length': 77, 'contact': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])}\n",
      "Loading data from /home/fkli/RNAdata/bpRNA_lasted/batching/test\n",
      "torch.Size([128, 1, 80, 80])\n",
      "torch.Size([128, 80, 4])\n",
      "torch.Size([128, 17, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/fkli/RNAdata/bpRNA_lasted/batching\"\n",
    "with open(join(DATA_PATH, \"test/0_128_80.pkl\"),\"rb\") as f:\n",
    "    da = pickle.load(f)\n",
    "print(da[0])\n",
    "train = RNADataset([join(DATA_PATH, \"test\")], upsampling=False)\n",
    "print(train[0][0].shape)\n",
    "print(train[0][6].shape)\n",
    "print(train[0][1].shape)\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train,\n",
    "#     batch_size=1,\n",
    "#     shuffle=True,\n",
    "#     num_workers=8,\n",
    "#     pin_memory=False,\n",
    "#     drop_last=True,\n",
    "# )\n",
    "# print(len(train_loader))\n",
    "# a, *_ = train_loader\n",
    "# print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.get_base_info import get_base_info_list\n",
    "seq = da[0]['seq_raw']\n",
    "m = get_base_info_list(seq)\n",
    "print(np.array(m).shape)\n",
    "mo = RNAUNet(17,2,1,unet_path)\n",
    "base_info_array = np.stack(m, axis=0)\n",
    "base_info = torch.tensor(base_info_array).float()\n",
    "print(mo(base_info))\n",
    "print(mo(base_info).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/fkli/RNAdata/bpRNA_lasted/data/train\"\n",
    "for file in os.listdir(data_path):\n",
    "    with open(join(data_path, file), \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data[3]['base_info'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "base_path = \"/home/fkli/RNAdata\"\n",
    "with open(base_path + '/RNAcmap2_231.pkl', 'rb') as f:\n",
    "    true_labels_pdb = pkl.load(f)\n",
    "data_nums = len(true_labels_pdb)\n",
    "print(data_nums, true_labels_pdb[0])\n",
    "\n",
    "model = RNAESM2(esm_path)\n",
    "model.eval()\n",
    "\n",
    "def pred_map_to_pair(pred_contact_map, seq_len):\n",
    "    pair_list = [[i, j, pred_contact_map[i][j]] for i in range(seq_len) for j in range(i)]\n",
    "    pair_list.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [[x[1], x[0]] for x in pair_list]\n",
    "count = 0\n",
    "save_all_bps = []\n",
    "for data in true_labels_pdb:\n",
    "    true_pairs = [i for i in data[3] if abs(i[0]-i[1]) > 3]  # non-local base-pairs\n",
    "    # print(true_pairs)\n",
    "    L = len(data[2])\n",
    "    # print(f\"count is {count}, seq is {data[2]}, seq len is {L}\")\n",
    "    with torch.no_grad ():\n",
    "        p_contact = model([data[2]])['contacts'].cpu().float()\n",
    "    p_contact = torch.Tensor.tolist(p_contact.squeeze())\n",
    "    pair_list = pred_map_to_pair(p_contact, L)\n",
    "    n = int(L/2)\n",
    "    positive_pairs = pair_list[:]\n",
    "    # print(positive_pairs)\n",
    "    negative_pairs = pair_list[n:]\n",
    "    tp = 0;fp = 0;fn = 0\n",
    "    correct_pairs = []\n",
    "    for i,I in enumerate(positive_pairs):\n",
    "        if I in true_pairs:\n",
    "            tp +=1\n",
    "            correct_pairs.append(I)\n",
    "        elif I not in true_pairs:\n",
    "            fp += 1\n",
    "            # print(tp)\n",
    "    for i,I in enumerate(true_pairs):\n",
    "        if I not in positive_pairs:\n",
    "            fn += 1\n",
    "    tn = L*L- tp - fp - fn\n",
    "\n",
    "    try:\n",
    "        pre = tp / (tp + fp)\n",
    "        sen = tp / (tp + fn)\n",
    "        f1 = 2*((pre*sen)/(pre + sen))\n",
    "        #with np.errstate(invalid='ignore'):\n",
    "        mcc = ((tp * tn) - (fp * fn)) / np.sqrt(np.float64((tp + fp) * (tp + fn) * (tn + fn) * (tn + fp)))\n",
    "    except:\n",
    "        pre = 0\n",
    "        sen = 0\n",
    "        f1 = 0\n",
    "        mcc = 0; #print(k)\n",
    "    save_all_bps.append([f1, pre, sen])\n",
    "    count += 1\n",
    "all_metrics = np.mean(save_all_bps, axis=0) \n",
    "print(all_metrics, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_map = [[1, 0, 1],  \n",
    "                 [0.1, 1, 0], \n",
    "                 [0.7, 0.4, 1.9]]\n",
    "def pred_map_to_pair(pred_contact_map, seq_len):\n",
    "    pair_list = [[i, j, pred_contact_map[i][j]] for i in range(seq_len) for j in range(i)]\n",
    "    pair_list.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [[x[0], x[1]] for x in pair_list]\n",
    "\n",
    "pair_list = pred_map_to_pair(predicted_map, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "datasets_path = \"/home/fkli/Projects/RNADiffusion/dataset/dataset.pkl\"\n",
    "with open(datasets_path, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_seq_len_list = [len(seq[2]) for seq in dataset[\"train_dataset\"]]\n",
    "train_seq_len_list.sort()\n",
    "train_seq_num = len(train_seq_len_list)\n",
    "print(f\"train seq num: {train_seq_num}\")\n",
    "my_x_ticks = np.arange(0, max(train_seq_len_list)+80, 80)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.xlabel('seq length')\n",
    "plt.ylabel('seq num')\n",
    "plt.hist(train_seq_len_list, bins=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils.data import padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def rna_evaluation(preds, targets):\n",
    "    preds = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "    tp = torch.sum(preds * targets)\n",
    "    tn = torch.sum((1 - preds) * (1 - targets))\n",
    "    fp = torch.sum(preds * (1 - targets))\n",
    "    fn = torch.sum((1 - preds) * targets)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) # accuracy\n",
    "    prec = tp / (tp + fp)  # precision\n",
    "    recall = tp / (tp + fn)  # recall\n",
    "    sens = tp / (tp + fn)  # senstivity\n",
    "    spec = tn / (tn + fp)  # spec\n",
    "\n",
    "    F1 = 2 * ((prec * sens) / (prec + sens))\n",
    "    MCC = (tp * tn - fp * fn) / torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return accuracy, prec, recall, sens, spec, F1, MCC.cpu().item()\n",
    "    \n",
    "def padding_two(data_array, maxlen):\n",
    "    a, b = data_array.shape\n",
    "    # np.pad(array, ((before_1,after_1),……,(before_n,after_n),module)\n",
    "    return np.pad(data_array, ((0, maxlen - a), (0, maxlen - b)), \"constant\")\n",
    "\n",
    "d_path = \"/home/fkli/RNAdata/RNAcmap2/datasets/test\"\n",
    "i = 0\n",
    "FF = 0\n",
    "PP = 0\n",
    "model = RNAESM2(esm_path)\n",
    "model.eval()\n",
    "for file in os.listdir(d_path):\n",
    "    i += 1\n",
    "    file_name = os.path.join(d_path, file)\n",
    "\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    str = [seq_data[\"seq_raw\"] for seq_data in dataset]\n",
    "    seq_max_len = max(len(seq) for seq in str)\n",
    "    with torch.no_grad ():\n",
    "        p_contact = model(str, seq_max_len)['contacts'].cpu().float()\n",
    "    contact_map = [padding_two(seq_data[\"contact\"], seq_max_len) for seq_data in dataset]\n",
    "    test_no_train_tmp = [rna_evaluation( p_contact[i], contact_map[i]) for i in range(p_contact.shape[0])]\n",
    "    accuracy, prec, recall, sens, spec, F1, MCC = zip(*test_no_train_tmp)\n",
    "    precision = np.average(np.nan_to_num(np.array(prec)))\n",
    "    F1 = np.average(np.nan_to_num(np.array(F1)))\n",
    "    PP += precision\n",
    "    FF += F1\n",
    "    torch.cuda.empty_cache()\n",
    "print(FF/i, PP/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.model import DiffusionRNA2dPrediction\n",
    "from models.rna_model.config import TransformerConfig, OptimizerConfig, Config, DataConfig, ProduceConfig, TrainConfig, LoggingConfig\n",
    "esm_path = \"/home/fkli/RNAm/RNA-ESM2-trans-2a100-mappro-KDNY-epoch_06-valid_F1_0.564.ckpt\"\n",
    "model = DiffusionRNA2dPrediction(\n",
    "    num_classes=2,\n",
    "    diffusion_dim=8,\n",
    "    cond_dim=8,\n",
    "    diffusion_steps=20,\n",
    "    dp_rate=0.0,\n",
    "    u_ckpt=\"/home/fkli/RNAm/ufold_train_alldata.pt\",\n",
    "    esm_ckpt=esm_path,\n",
    ")\n",
    "ckpt_path = '/home/fkli/RNAm/best_checkpoint_15.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(\"cuda:3\")\n",
    "print('load model from {}'.format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common.data_utils import contact_map_masks\n",
    "from torch.utils.data import DataLoader\n",
    "from data.data_generator import RNADataset, diff_collate_fn\n",
    "from functools import partial\n",
    "from common.loss_utils import rna_evaluation\n",
    "DATA_PATH = \"/home/fkli/RNAdata/RNAcmap2/datasets\"\n",
    "partial_collate_fn = partial(diff_collate_fn)\n",
    "test = RNADataset([os.path.join(DATA_PATH, \"test\")], upsampling=False)\n",
    "test_loader = DataLoader(\n",
    "    test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=partial_collate_fn,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "device = torch.device(\"cuda:3\")\n",
    "def model_test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_no_train = list()\n",
    "        total_name_list = list()\n",
    "        total_length_list = list()\n",
    "\n",
    "        for _, (contact, base_info, data_seq_raw, data_length, data_name, set_max_len, data_seq_encoding) in enumerate(test_loader):\n",
    "            total_name_list += [item for item in data_name]\n",
    "            total_length_list += [item.item() for item in data_length]\n",
    "\n",
    "            base_info = base_info.to(device)\n",
    "            matrix_rep = torch.zeros_like(contact)\n",
    "            data_length = data_length.to(device)\n",
    "            # data_seq_raw = data_seq_raw.to(device)\n",
    "            data_seq_encoding = data_seq_encoding.to(device)\n",
    "            contact_masks = contact_map_masks(data_length, matrix_rep).to(device)\n",
    "\n",
    "            # calculate contact loss\n",
    "            batch_size = contact.shape[0]\n",
    "            pred_x0, _ = model.sample(batch_size, base_info, data_seq_raw, set_max_len, contact_masks, data_seq_encoding)\n",
    "\n",
    "            pred_x0 = pred_x0.cpu().float()\n",
    "            test_no_train_tmp = list(map(lambda i: rna_evaluation(\n",
    "                pred_x0[i].squeeze(), contact.float()[i].squeeze()), range(pred_x0.shape[0])))\n",
    "            test_no_train += test_no_train_tmp\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        accuracy, prec, recall, sens, spec, F1, MCC = zip(*test_no_train)\n",
    "\n",
    "        f1_pre_rec_df = pd.DataFrame({'name': total_name_list,\n",
    "                                        'length': total_length_list,\n",
    "                                        'accuracy': list(np.array(accuracy)),\n",
    "                                        'precision': list(np.array(prec)),\n",
    "                                        'recall': list(np.array(recall)),\n",
    "                                        'sensitivity': list(np.array(sens)),\n",
    "                                        'specificity': list(np.array(spec)),\n",
    "                                        'f1': list(np.array(F1)),\n",
    "                                        'mcc': list(np.array(MCC))})\n",
    "\n",
    "        accuracy = np.average(np.nan_to_num(np.array(accuracy)))\n",
    "        precision = np.average(np.nan_to_num(np.array(prec)))\n",
    "        recall = np.average(np.nan_to_num(np.array(recall)))\n",
    "        sensitivity = np.average(np.nan_to_num(np.array(sens)))\n",
    "        specificity = np.average(np.nan_to_num(np.array(spec)))\n",
    "        F1 = np.average(np.nan_to_num(np.array(F1)))\n",
    "        MCC = np.average(np.nan_to_num(np.array(MCC)))\n",
    "\n",
    "        print('#' * 40)\n",
    "        print('Average testing accuracy: ', round(accuracy, 3))\n",
    "        print('Average testing F1 score: ', round(F1, 3))\n",
    "        print('Average testing precision: ', round(precision, 3))\n",
    "        print('Average testing recall: ', round(recall, 3))\n",
    "        print('Average testing sensitivity: ', round(sensitivity, 3))\n",
    "        print('Average testing specificity: ', round(specificity, 3))\n",
    "        print('#' * 40)\n",
    "        print('Average testing MCC', round(MCC, 3))\n",
    "        print('#' * 40)\n",
    "        print('')\n",
    "    \n",
    "    return {'f1': F1, 'precision': precision, 'recall': recall, 'sensitivity': sensitivity, 'specificity': specificity, 'accuracy': accuracy, 'mcc': MCC}, f1_pre_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test()\n",
    "# f1_pre.to_csv(\n",
    "#     os.path.join(\"/home/fkli/\", f\"test.csv\"),\n",
    "#     index=False,\n",
    "#     header=False,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNADiffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
